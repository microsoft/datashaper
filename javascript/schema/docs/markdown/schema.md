<!-- Do not edit this file. It is automatically generated by API Documenter. -->

[Home](./index.md) &gt; [@datashaper/schema](./schema.md)

## schema package

## Enumerations

|  Enumeration | Description |
|  --- | --- |
|  [BinStrategy](./schema.binstrategy.md) |  |
|  [BooleanComparisonOperator](./schema.booleancomparisonoperator.md) |  |
|  [BooleanOperator](./schema.booleanoperator.md) |  |
|  [DataFormat](./schema.dataformat.md) | Base format the data is stored within. This will expand to include additional formats such as Arrow and Parquet over time. TODO: we've seen a number of examples in the wild using JSON Lines https://jsonlines.org/ |
|  [DataNature](./schema.datanature.md) | Indicates the expected general layout of the data. This could be used to provide validation hints. For example, microdata must have one row per subject. TODO: "timeseries" as distinct from "panel"? others? |
|  [DataOrientation](./schema.dataorientation.md) | <p>Indicates the orientation of the data within the file.</p><p>Most CSV data files are 'values' (row-oriented).</p><p>JSON files can commonly be either. Records are probably more common, though require more space due to replication of keys. Apache Arrow or Parquet are columnar. This nearly aligns with pandas: https://pandas.pydata.org/pandas-docs/stable/user\_guide/io.html\#json</p><p>A key difference (which probably needs resolved) is that we don't yet support the notion of an index. See their example for "columns" or "index" orientation, which is a nested structure.</p><p>Example JSON formats: values: \[ \["colA", "colB"\], \["valueA1", "valueA2"\], \["valueA2", "valueB2"\] \] records: \[{ colA: valueA1, colB: valueB1 }<!-- -->, { colA: valueA2, colB: valueB2 }<!-- -->\] columnar: { colA: \[valueA1, valueA2\], colB: \[valueB1, valueB2\] }</p> |
|  [DataType](./schema.datatype.md) | Explicit data type of the value (i.e., for a column or property). TODO: clarify/update null/undefined |
|  [DateComparisonOperator](./schema.datecomparisonoperator.md) |  |
|  [FieldAggregateOperation](./schema.fieldaggregateoperation.md) | This is the subset of aggregate functions that can operate on a single field so we don't accommodate additional args. See https://uwdata.github.io/arquero/api/op\#aggregate-functions |
|  [FilterCompareType](./schema.filtercomparetype.md) |  |
|  [JoinStrategy](./schema.joinstrategy.md) |  |
|  [MathOperator](./schema.mathoperator.md) |  |
|  [MergeStrategy](./schema.mergestrategy.md) |  |
|  [NumericComparisonOperator](./schema.numericcomparisonoperator.md) |  |
|  [ParseType](./schema.parsetype.md) | This is a subset of data types available for parsing operations |
|  [SetOp](./schema.setop.md) |  |
|  [SortDirection](./schema.sortdirection.md) |  |
|  [StringComparisonOperator](./schema.stringcomparisonoperator.md) |  |
|  [VariableNature](./schema.variablenature.md) | Describes the semantic shape of a variable. This has particular effect on how we display and compare data, such as using line charts for continuous versus bar charts for categorical. This mostly applies to numeric variables, but strings for instance can be categorial. |
|  [Verb](./schema.verb.md) |  |
|  [WindowFunction](./schema.windowfunction.md) | These are operations that perform windowed compute. See https://uwdata.github.io/arquero/api/op\#window-functions |

## Functions

|  Function | Description |
|  --- | --- |
|  [createCodebookSchemaObject(input)](./schema.createcodebookschemaobject.md) |  |
|  [createDataPackageSchemaObject(input)](./schema.createdatapackageschemaobject.md) |  |
|  [createDataTableSchemaObject(input)](./schema.createdatatableschemaobject.md) |  |
|  [createWorkflowSchemaObject(input)](./schema.createworkflowschemaobject.md) |  |

## Interfaces

|  Interface | Description |
|  --- | --- |
|  [AggregateArgs](./schema.aggregateargs.md) |  |
|  [BasicInput](./schema.basicinput.md) | Single-input, single-output step I/O |
|  [Bin](./schema.bin.md) |  |
|  [BinArgs](./schema.binargs.md) |  |
|  [BinarizeArgs](./schema.binarizeargs.md) |  |
|  [BooleanArgs](./schema.booleanargs.md) |  |
|  [Category](./schema.category.md) |  |
|  [CodebookSchema](./schema.codebookschema.md) | This contains all of the field-level details for interpreting a dataset, including data types, mapping, and metadata. Note that with persisted metadata and field examples, a dataset can often be visualized and described to the user without actually loading the source file. resource profile: 'codebook' |
|  [Constraints](./schema.constraints.md) | Validation constraints for a field. |
|  [ConvertArgs](./schema.convertargs.md) |  |
|  [Criterion](./schema.criterion.md) |  |
|  [DataPackageSchema](./schema.datapackageschema.md) | Defines a Data Package, which is a collection of data resources such as files and schemas. Loosely based on the Frictionless spec, but modified where needed to meet our needs. https://specs.frictionlessdata.io/data-package/ |
|  [DataShape](./schema.datashape.md) | Defines parameters for understanding the logical structure of data contents. |
|  [DataTableSchema](./schema.datatableschema.md) | This defines the table-containing resource type. A dataset can be embedded directly using the <code>data</code> property, or it can be linked to a raw file using the <code>path</code>. If the latter, optional format and parsing options can be applied to aid interpreting the file contents. resource profile: 'datatable' |
|  [DecodeArgs](./schema.decodeargs.md) |  |
|  [DeriveArgs](./schema.deriveargs.md) |  |
|  [DualInput](./schema.dualinput.md) | Dual-input, single-output step I/O |
|  [EncodeArgs](./schema.encodeargs.md) |  |
|  [EraseArgs](./schema.eraseargs.md) |  |
|  [FetchArgs](./schema.fetchargs.md) |  |
|  [Field](./schema.field.md) | Contains the full schema definition and metadata for a data field (usually a table column). This includes the required data type, various data nature and rendering properties, potential validation rules, and mappings from a data dictionary. |
|  [FieldMetadata](./schema.fieldmetadata.md) | Holds core metadata/stats for a data field. |
|  [FillArgs](./schema.fillargs.md) |  |
|  [FilterArgs](./schema.filterargs.md) |  |
|  [FoldArgs](./schema.foldargs.md) |  |
|  [ImputeArgs](./schema.imputeargs.md) |  |
|  [InputColumnArgs](./schema.inputcolumnargs.md) |  |
|  [InputColumnListArgs](./schema.inputcolumnlistargs.md) | Base interface for a number of operations that work on a column list. |
|  [InputColumnRecordArgs](./schema.inputcolumnrecordargs.md) |  |
|  [InputKeyValueArgs](./schema.inputkeyvalueargs.md) |  |
|  [JoinArgs](./schema.joinargs.md) |  |
|  [JoinArgsBase](./schema.joinargsbase.md) |  |
|  [LookupArgs](./schema.lookupargs.md) |  |
|  [MergeArgs](./schema.mergeargs.md) |  |
|  [Named](./schema.named.md) | Base interface for sharing properties of named resources/objects. |
|  [NamedOutputPortBinding](./schema.namedoutputportbinding.md) | An explicit workflow output |
|  [NamedPortBinding](./schema.namedportbinding.md) | An explicit step input binding |
|  [OnehotArgs](./schema.onehotargs.md) |  |
|  [OrderbyArgs](./schema.orderbyargs.md) |  |
|  [OrderbyInstruction](./schema.orderbyinstruction.md) |  |
|  [OutputColumnArgs](./schema.outputcolumnargs.md) |  |
|  [ParserOptions](./schema.parseroptions.md) | Parsing options for delimited files. This is a mix of the options from pandas and spark. |
|  [PivotArgs](./schema.pivotargs.md) |  |
|  [RecodeArgs](./schema.recodeargs.md) |  |
|  [ResourceSchema](./schema.resourceschema.md) | Parent class for any resource type understood by the system. Any object type that extends from Resouce is expected to have a standalone schema published. For project state, this can be left as generic as possible for now. |
|  [RollupArgs](./schema.rollupargs.md) |  |
|  [SampleArgs](./schema.sampleargs.md) |  |
|  [SpreadArgs](./schema.spreadargs.md) |  |
|  [StepJsonCommon](./schema.stepjsoncommon.md) | Common step properties |
|  [TypeHints](./schema.typehints.md) | Configuration values for interpreting data types when parsing a delimited file. By default, all values are read as strings - applying these type hints can derive primitive types from the strings. |
|  [UnhotArgs](./schema.unhotargs.md) |  |
|  [VariadicInput](./schema.variadicinput.md) | Multi-input, single output step I/O |
|  [WindowArgs](./schema.windowargs.md) |  |
|  [WorkflowSchema](./schema.workflowschema.md) | The root wrangling workflow specification. resource profile: 'workflow' |

## Variables

|  Variable | Description |
|  --- | --- |
|  [LATEST\_CODEBOOK\_SCHEMA](./schema.latest_codebook_schema.md) |  |
|  [LATEST\_DATAPACKAGE\_SCHEMA](./schema.latest_datapackage_schema.md) |  |
|  [LATEST\_DATATABLE\_SCHEMA](./schema.latest_datatable_schema.md) |  |
|  [LATEST\_WORKFLOW\_SCHEMA](./schema.latest_workflow_schema.md) |  |

## Type Aliases

|  Type Alias | Description |
|  --- | --- |
|  [DedupeArgs](./schema.dedupeargs.md) |  |
|  [FactoryInput](./schema.factoryinput.md) |  |
|  [GroupbyArgs](./schema.groupbyargs.md) |  |
|  [OutputPortBinding](./schema.outputportbinding.md) |  |
|  [PortBinding](./schema.portbinding.md) |  |
|  [RenameArgs](./schema.renameargs.md) |  |
|  [SelectArgs](./schema.selectargs.md) |  |
|  [Step](./schema.step.md) | Specification for step items |
|  [UnfoldArgs](./schema.unfoldargs.md) |  |
|  [UnrollArgs](./schema.unrollargs.md) |  |
|  [Value](./schema.value.md) | A cell/property value of any type. |

